多级缓存,是指在整个系统架构的不同系统层级进行数据缓存,以提升访问效率.

>一般系统整体流程如下:
1. 接入`Nginx`将请求负载均衡到应用`Nginx`,此处常用的负载均衡算法是轮询或者一致性哈希;
  + `轮询可以使服务器的请求更加均衡`;
  + `一致性哈希可以提升应用Nginx的缓存命中率`;
2. 应用`Nginx`读取本地缓存,如果本地缓存命中,则直接返回,使用应用`Nginx`本地缓存可以提升整体的吞吐量,降低后端压力,尤其应对热点问题非常有效;
  + 可以使用`Lua Shared Dict`/`Nginx Proxy Cache(磁盘/内存)`/`Local Redis实现`;
3. 如果`Nginx`本地缓存没命中,则会读取相应的分布式缓存;如果分布式缓存命中,则直接返回相应数据(并回写到`Nginx`本地缓存);
  + 如`Redis`缓存,还可以考虑使用主从架构来提升性能和吞吐量;
4. 如果分布式缓存也没有命中,则会回源到`Tomcat`集群,在回源到`Tomcat`集群时,也可以使用轮询和一致性哈希作为负载均衡算法;
5. 在`Tomcat`应用中,首先读取本地堆缓存.如果有,则直接返回(并会写到主`Redis`集群);
6. 作为可选部分,如果步骤4没有命中,则可以再尝试一次读主`Redis`集群操作,目的是防止当从集群有问题时的流量冲击;
7. 如果所有缓存都没有命中,则只能查询`DB`或相关服务获取相关数据并返回.
8. 步骤7返回的数据异步写到主`Redis`集群,此处可能有多个`Tomcat`实例同时写主`Redis`集群,会造成数据错乱.


**`整体分了三部分缓存:应用Nginx本地缓存,分布式缓存,Tomcat堆缓存;`**
+ `应用Nginx本地缓存` : 用来解决热点缓存问题
+ `分布式缓存` : 用来减少访问回源率
+ `Tomcat堆缓存` : 用于防止相关缓存失效/崩溃之后的冲击


## `如何缓存数据`

**对于缓存的数据,可以考虑不过期缓存和带过期时间缓存;什么场景应该选择哪种模式需要根据业务和数据量等因素来决定;**


+ `不过期缓存` 
  + 使用`Cache-Aside`模式,首先写数据库,如果成功,则写缓存.
    + 这种场景下存在事务成功/缓存写失败但无法回滚事务的情况.
  + 不要把写缓存放在事务中,尤其写分布式缓存,因为网络抖动可能导致写缓存响应时间很慢,引起数据库事务阻塞.
    + 如果对缓存数据一致性要求不是那么高,数据量也不是很大,则可以考虑定期全量同步缓存;
  + 对于长尾访问的数据/大多数数据访问频率都很高的场景,或者是缓存空间足够,都可以考虑不过期缓存;
    + 当缓存满了,可以考虑用`LRU`机制驱逐老的缓存数据;

+ `过期缓存`,如采用懒加载,一般用于缓存其他系统的数据/缓存空间有限/低频热点缓存等场景.
  + 首先读取缓存,如果不命中,则查询数据,然后异步写入缓存并设置过期时间,下次读取将命中缓存;
  + **`热点数据经常使用过期缓存,即在应用系统上缓存比较短的时间;这种缓存可能存在一段时间的数据不一致情况,需要根据场景来决定如何设置过期时间.`**

+ `热点缓存`
  + `热点缓存`,如果每次都去远程缓存系统中获取,可能会因为访问量太大导致远程缓存系统请求过多,负载过高或者带宽过高等问题;
  + 可以通过挂更多的从缓存,客户端通过负载均衡机制读取从缓存系统数据.

## `分布式缓存与应用负载均衡`

**`缓存分布式`,一般采用分片实现,即将数据分散到多个实例或多台服务器.**
+ 算法一般采用取模和一致性哈希;
+ 对于不过期缓存机制,可以考虑取模机制,扩容时一般是新建一个集群;
+ 对于可以丢失的缓存数据,可以考虑一致性哈希,即使其中一个实例出问题只是丢一小部分;
+ 对于分片实现可以考虑客户端实现,或者使用如`Twemproxy`中间件进行代理(分片对客户端是透明);
+ 如果使用`Redis`,可以考虑使用`redis-cluster`分布式集群方案;


**`应用负载均衡`一般采用轮询和一致性哈希:**
+ 一致性哈希可以根据应用请求的`URL`或者`URL参数`将相同的请求转发到同一个节点;
  + 命中率不会因为增加服务器而降低.
  + 相同的请求会转发到同一台服务器,造成某台服务器负载过重,甚至因为请求太多导致服务出现问题;
+ 轮询是将请求均匀地转发到每个服务器;
  + 每个服务器的负载基本均衡.
  + 随着服务器的增加,缓存的命中率会下降;

>根据实际情况动态选择使用哪种算法:
+ 负载较低时,使用一致性哈希
+ 热点请求降级一致性哈希为轮询,或者如果请求数据有规律,则可考虑带权重的一致性哈希;
+ 将热点数据推送到接入层`Nginx`,直接响应给用户;

## `热点数据与更新缓存`

热点数据会造成服务器压力过大,导致服务器性能/吞吐量/带宽达到极限,出现响应慢或者拒绝服务的情况;

+ `单机全量缓存+主从`
  + 所有缓存都存储在应用本机,回源之后会把数据更新到`主Redis集群`
  + 然后通过主从模式复制到其他`从Redis集群`;
  + 缓存的更新可以采用懒加载或者订阅消息进行同步;


+ `分布式缓存+应用本地热点`
  + 对于分布式缓存,需要出`Nginx+Lua`应用中进行应用缓存来减少`Redis集群`的访问冲击;
  + 首先查询应用本地缓存,如果命中,则直接缓存;
  + 如果没有命中,则接着查询`Redis集群`,回源到`Tomcat`,然后将数据缓存到应用本地;


对于`LVS+HAProxy`到应用`Nginx`的负载机制,正常情况采用一致性哈希,如果某个请求类型的访问量突破了一定的阈值,则自动降级为轮询机制;

**`实际场景中可以通过两级Nginx(接入Nginx->应用Nginx)`与建立实时热点发现系统来发现热点:**
+ 接入`Nginx`将请求转发给应用`Nginx`;
+ 应用`Nginx`首先读取本地缓存;
  + 如果命中,则直接返回,不命中会读取分布式缓存,回源到`Tomcat`进行处理;
+ 应用`Nginx`会将请求上报给实时热点发现系统;
  + 如使用`UDP`直接上报请求,或者将请求写到本地`kafka`,或者使用`flume`订阅本地`Nginx`日志.
  + 上报给实时热点发现系统后,它将进行热点统计(可以考虑`storm`实时计算)
+ 根据设置的阈值将热点数据推送到应用`Nginx`本地缓存:
  + **`因为做了本地缓存,需要考虑数据一致性,即何时失效或更新缓存;`**
    + 如果可以订阅数据变更消息,那么建议订阅变更消息以进行缓存更新;
    + 如果无法订阅消息或者订阅消息成本比较高,并且对短暂的数据一致性要求不严格,那么可以设置合理的过期时间,过期后再查询新的数据;
    + 如果是秒杀之类的,可以订阅活动开启消息,将相关数据提前推送到前端应用,并将负载均衡机制降级为轮询;
    + 建立实时热点发现系统来热点进行统一推送和更新;

## `更新缓存与原子性`

如果多个应用同时操作一份数据,很可能导致缓存数据变成脏数据:
+ 更新数据时使用更新时间戳或者版本对比,如果使用`Redis`,则可以利用其单线程机制进行原子化更新;
+ 使用如`canal`订阅数据库`binlog`;
+ 将更新请求按照相应的规则分散到多个队列,然后每个队列进行单线程更新,更新时拉取最新的数据保存;
+ 用分布式锁,在更新之前获取相关的锁;

## `缓存崩溃与快速修复`

+ **`取模`** : 
  + 对于取模机制,如果其中一个实例坏了,摘除此实例将导致大量缓存不命中,则瞬间大流量可能导致后端`DB/服务`出现问题;
    + 针对这种情况,可以采用主从机制来避免实例坏了的问题;
    + 取模机制下增加节点将导致大量缓存不命中,**一般是建立另一个集群,然后把数据迁移到新集群,把流量迁移过去**;

+ **`一致性哈希`** : 对于一致性哈希机制,如果其中一个实例坏了,摘除此实例只影响一致性哈希环上的部分缓存不命中,不会导致大量缓存瞬间回源到后端`DB/服务`;
  + 若一些误操作导致整个缓存集群出现问题:
    + `主从机制`,做好冗余,即其中一部分不可用,将对等的部分补上去;
    + 如果因为缓存导致应用可用性已经下降,可以考虑部分用户降级,然后慢慢减少降级量,后台通过`Worker`预热缓存数据;

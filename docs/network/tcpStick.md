## 产生`tcp`粘包和拆包的原因

我们知道`tcp`是以流动的方式传输数据，传输的最小单位为一个报文段（segment）。

`tcp Header`中有个`Options`标识位，常见的标识为`mss(Maximum Segment Size最大消息长度)`指的是，**连接层每次传输的数据有个最大限制`MTU(Maximum Transmission Unit)`，一般是1500比特，超过这个量要分成多个报文段，`mss`则是这个最大限制减去`TCP`的`header`，光是要传输的数据的大小，一般为1460比特**。换算成字节，也就是180多字节。

```
MSS = MTU - header 
```

`tcp`为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。

>发生`TCP`粘包、拆包主要是由于下面一些原因：
+ 应用程序写入的数据大于套接字缓冲区大小，这将会发生`拆包`。
+ 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生`粘包`。
+ 进行`mss（最大报文长度）`大小的`TCP`分段，当`TCP`报文长度-`TCP`头部长度>`mss`的时候将发生`拆包`。
+ 接收方法不及时读取套接字缓冲区数据，这将发生粘包。

### 如何解决拆包粘包

既然知道了`tcp`是无界的数据流，且协议本身无法避免粘包，拆包的发生，那我们只能在应用层数据协议上，加以控制。

>通常在制定传输数据时，可以使用如下方法：
+ 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
+ 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。
+ 设置消息边界，服务端从网络流中按消息编辑分离出消息内容。

## 问题：

`TCP`是以段为单位进行数据包的发送的。
+ 在建立`TCP`连接的同时，也可以确定发送数据包的单位，称之为"最大消息长度"：`MSS`。
  + 最理想的情况是，最大消息长度`MSS`正好是`IP`层中不被分片处理的最大数据长度。
+ `TCP`在传送大量数据的时候，是以`段=MSS的大小`将数据进行分割发送的，进行重发时也是以`MSS`为单位的。
+ 最大消息长度——`MSS`是在三次握手的时候，在两端主机之间被计算得出的。
  + 两端主机在发出"建立`TCP`连接请求的`SYN`包"时，会在SYN包的`TCP`首部中写入`MSS`选项，告诉对方自己所能够适应的`MSS`的大小，然后发送端主机会在两者之间选择一个较小的`MSS`值投入使用。

### `TCP`为什么引入接受缓存这个数据结构？

如果没有接受缓存的话，或者说只有一个缓存的话，为了保证接受的数据是按顺序传输的，所以如果位于x序号之后的序号分组先到达目的主机的运输层的话必然丢弃，这样的话将在重传上花费很大的开销，所以一般如果有过大的序号达到接收端，那么会按照序号缓存起来等待之前的序号分许到达，然后一并交付到应用进程。

 

## `TCP` 粘包/拆包的原因及解决方法

`TCP`是以流的方式来处理数据，一个完整的包可能会被`TCP`拆分成多个包进行发送，也可能把小的封装成一个大的数据包发送。

`TCP`粘包/分包的原因：

应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生拆包现象，而应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包现象；

进行MSS大小的`TCP`分段，当`TCP`报文长度-`TCP`头部长度>MSS的时候将发生拆包

以太网帧的payload（净荷）大于MTU（1500字节）进行ip分片。

 
### 解决方法

消息定长：`FixedLengthFrameDecoder`类

包尾增加特殊字符分割：行分隔符类：`LineBasedFrameDecoder`或自定义分隔符类 ：`DelimiterBasedFrameDecoder`

将消息分为消息头和消息体：`LengthFieldBasedFrameDecoder`类。

分为有头部的拆包与粘包、长度字段在前且有头部的拆包与粘包、多扩展头部的拆包与粘包。
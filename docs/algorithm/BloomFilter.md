布隆过滤器(bloom filter)是非常经典的，以空间换时间的算法。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

## 设计思路

### 算法思想

计算某元素x是否在一个集合中，首先能想到的方法就是将所有的已知元素保存起来构成一个集合R，然后用元素x跟这些R中的元素一一比较来判断是否存在于集合R中；我们可以采用链表等数据结构来实现。但是，随着集合R中元素的增加，其占用的内存将越来越大。试想，如果有几千万个不同网页需要下载，所需的内存将足以占用掉整个进程的内存地址空间。即使用MD5，UUID这些方法将URL转成固定的短小的字符串，内存占用也是相当巨大的。

于是，我们会想到用Hash table的数据结构，运用一个足够好的Hash函数将一个URL映射到二进制位数组（位图数组）中的某一位。如果该位已经被置为1，那么表示该URL已经存在。

但是Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想;

![guava_bloomfilter_1](/images/guava_bloomfilter_1.png)

+ 首先创建一个非常长的二进制数组
+ 通过随机映射函数将数据分配在不同的数据位置上
+ 将这个位置的字节从0变为1

可以看到这里面最关键的地方就是，随机映射函数的使用。

我们首先希望数据可以平均分配在这个数组上，同时速度必须要快。这种情况，最合适的是hash算法，guava中使用的hash算法，是`murmurhash`，于2008年被发明。这个算法hbase,redis,kafka都在使用。

既然选用hash算法，必然就会存在碰撞的可能。两个不完全相同的值计算出来的hash值难免会一致。多次使用hash算法，为同一个值取不同的多个hash，取的越多。碰撞率的几率就越小。

例下图，每个值取三次hash，分布映射在数组的不同位置。

![guava_bloomfilter_2](/images/guava_bloomfilter_2.png)

>通过以上描述，我们就产生了一个问题，带入场景，我们预估有10W的用户量，且希望误报率限制在 万分之一(0.0001)。那么到底需要多少个hash函数个数(k)，及需要多大的数组长度(m)呢？

公式： `m = -(n * lnfpp)/(ln2)^2` `k = (m / n) * ln2`

>变量定义：
+ `k`: hash函数个数
+ `fpp`: 误报率
+ `m`: 二进制数组大小
+ `n`: 预估的数据量大小

带入公式，我们可以求得 存储1w的用户量需要187kb数据存储空间，使用13个hash将碰撞率将为万分之一。错误率要求越低，空间要求越少。


## 缺陷

1. Bloom Filter无法从Bloom Filter集合中删除一个元素。因为该元素对应的位会牵动到其他的元素。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。 此外，Bloom Filter的hash函数选择会影响算法的效果。

2. 还有一个比较重要的问题，如何根据输入元素个数n，确定位数组m的大小及hash函数个数，即hash函数选择会影响算法的效果。当hash函数个数`k=(ln2)*(m/n)`时错误率最小。在错误率不大于E的情况 下，m至少要等于 `n * lg(1/E)` 才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应该`>=n * lg(1/E)*lge` ，大概就是`n * lg(1/E)`1.44倍(lg表示以2为底的对数)。 

举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。（PS：这里m与n的单位不同，m是bit为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多bit的。所以使用bloom filter内存上通常都是节省的。 ）

一般BF可以与一些key-value的数据库（如redis）一起使用，来加快查询。由于BF所用的空间非常小，所有BF可以常驻内存。这样子的话，对于大部分不存在的元素，我们只需要访问内存中的BF就可以判断出来了，只有一小部分，我们需要访问在硬盘上的key-value数据库。从而大大地提高了效率。


## 应用

1. 垃圾邮件过滤

像网易,腾讯等公众电子邮件（email）提供商，总是需要过滤来自发送垃圾邮件的人（spamer）的垃圾邮件。

一个办法就是记录下那些发垃圾邮件的 email地址。由于那些发送者不停地在注册新的地址，全世界少说也有几十亿个发送垃圾邮件的地址，将他们都存起来则需要大量的网络服务器。

如果用哈希表，每存储一亿个 email地址，就需要`1.6GB`的内存（用哈希表实现的具体办法是将每一个 email地址对应成一个八字节的信息指纹，然后将这些信息指纹存入哈希表，由于哈希表的存储效率一般只有 50%，因此一个 email地址需要占用十六个字节。一亿个地址大约要 1.6GB，即十六亿字节的内存）。

因此存贮几十亿个邮件地址可能需要上百GB的内存。而Bloom Filter只需要哈希表 1/8到 1/4 的大小就能解决同样的问题。BloomFilter决不会漏掉任何一个在黑名单中的可疑地址。

而至于误判问题，常见的补救办法是在建立一个小的白名单，存储那些可能别误判的邮件地址

2. 网络应用
  1. P2P网络中查找资源操作，可以对每条网络通路保存Bloom Filter，当命中时，则选择该通路访问。
  2. 广播消息时，可以检测某个IP是否已发包。
  3. 检测广播消息包的环路，将Bloom Filter保存在包里，每个节点将自己添加入Bloom Filter。
  4. 信息队列管理，使用Counter Bloom Filter管理信息流量。

3. Hbase底层

Hbase也使用了Bloom Filter，以减少不存在的行或列在磁盘上的查询，大大提高了数据库的查询操作的性能。
## `zooKeeper`是什么？
`zooKeeper`是一个分布式的，开放源码的分布式应用程序协调服务，是Google的`Chubby`一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。

最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

## `zooKeeper`提供了什么？

>+ 文件系统
+ 通知机制

### `zooKeeper`文件系统

**每个子目录项如`NameService`都被称作为`znode`，和文件系统一样，我们能够自由的增加、删除`znode`，在一个`znode`下增加、删除子`znode`，唯一的不同在于`znode`是可以存储数据的。**

>有四种类型的znode： 
1. `PERSISTENT`：持久化目录节点 
	+ 客户端与`zooKeeper`断开连接后，该节点依旧存在 
2. `PERSISTENT_SEQUENTIAL`：持久化顺序编号目录节点 
	+ 客户端与`zooKeeper`断开连接后，该节点依旧存在，只是`zooKeeper`给该节点名称进行顺序编号 
3. `EPHEMERAL`：临时目录节点 
	+ 客户端与`zooKeeper`断开连接后，该节点被删除 
4. `EPHEMERAL_SEQUENTIAL`：临时顺序编号目录节点 
	+ 客户端与`zooKeeper`断开连接后，该节点被删除，只是`zooKeeper`给该节点名称进行顺序编号 


### `zooKeeper`通知机制

**客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，`zooKeeper`会通知客户端。**

### `zooKeeper`做了什么？

>1. `命名服务`
2. `配置管理`
3. `集群管理`
4. `分布式锁`
5. `队列管理`

#### `zooKeeper`命名服务

在`zooKeeper`的文件系统里创建一个目录，即有唯一的`path`。

在我们使用`tborg`无法确定上游程序的部署机器时即可与下游程序约定好`path`，通过`path`即能互相探索发现。

#### `zooKeeper`的配置管理

程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。

现在把这些配置全部放到`zooKeeper`上去，保存在 `zooKeeper` 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 `zooKeeper` 的通知，然后从 `zooKeeper` 获取新的配置信息应用到系统中就好；

#### `zooKeeper`集群管理

所谓集群管理无在乎两点：`是否有机器退出和加入`、`选举master`。 

对于第一点，所有机器约定在父目录`GroupMembers`下创建临时目录节点，然后监听父目录节点的子节点变化消息。

一旦有机器挂掉，该机器与 `zooKeeper`的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：**某个兄弟目录被删除，于是，所有人都知道：它上船了**。

新机器加入也是类似，所有机器收到通知：**新兄弟目录加入，`highcount`又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为`master`就好。**

#### `zooKeeper`分布式锁

有了`zooKeeper`的一致性文件系统，锁的问题变得容易。**锁服务可以分为两类，一个是保持独占，另一个是控制时序。**

对于第一类，我们将`zooKeeper`上的一个`znode`看作是一把锁，通过`createznode`的方式来实现。

所有客户端都去创建`/distribute_lock`节点，最终成功创建的那个客户端也即拥有了这把锁。**用完删除掉自己创建的`distribute_lock`节点就释放出锁。**

对于第二类，`/distribute_lock`已经预先存在，所有客户端在它下面创建**临时顺序编号目录节点**，和选`master`一样，编号最小的获得锁，用完删除，依次方便。

#### `zooKeeper`队列管理

>两种类型的队列：
1. 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 
2. 队列按照`FIFO`方式进行入队和出队操作。 

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 

第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。

#### 分布式与数据复制 

>`zooKeeper`作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 
1. 容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 
2. 提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 
3. 提高性能：让客户端本地访问就近的节点，提高用户访问速度。 

>从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 
1. 写主(`WriteMaster`) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 
2. 写任意(`Write Any`)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。

对`zooKeeper`来说，它采用的方式是写任意。

通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立`observer`的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。

#### `zooKeeper`角色描述
#### `zooKeeper`与客户端
#### `zooKeeper`设计目的

>1. `最终一致性`：client不论连接到哪个Server，展示给它都是同一个视图，这是`zooKeeper`最重要的性能。 
2. `可靠性`：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。 
3. `实时性`：`zooKeeper`保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，`zooKeeper`不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用`sync()`接口。 
4. `等待无关（wait-free）`：慢的或者失效的`client`不得干预快速的client的请求，使得每个`client`都能有效的等待。 
5. `原子性`：更新只能成功或者失败，没有中间状态。 
6. `顺序性`：包括全局有序和偏序两种：
  + 全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；
  + 偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 

#### `zooKeeper`工作原理

`zooKeeper` 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做`Zab`协议。

Zab协议有两种模式，它们分别是**恢复模式（选主）**和**广播模式（同步）**。

当服务启动或者在领导者崩溃后，`Zab`就进入了恢复模式，当领导者被选举出来，且大多数`Server`完成了和 `leader`的状态同步以后，恢复模式就结束了。

**状态同步保证了`leader`和`Server`具有相同的系统状态。**

为了保证事务的顺序一致性，`zooKeeper`采用了递增的事务id号（`zxid`）来标识事务。

所有的提议（`proposal`）都在被提出的时候加上了`zxid`。

实现中`zxid`是一个64位的数字，它高`32`位是`epoch`用来标识`leader`关系是否改变，每次一个`leader`被选出来，它都会有一个新的`epoch`，标识当前属于那个`leader`的统治时期。**低32位用于递增计数。**

#### `zooKeeper` 下 Server工作状态

>每个Server在工作过程中有三种状态： 
+ `LOOKING`：当前Server不知道leader是谁，正在搜寻
+ `LEADING`：当前Server即为选举出来的leader
+ `FOLLOWING`：leader已经选举出来，当前Server与之同步

#### `zooKeeper`选主流程(basic paxos)

**当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。**

>Zk的选举算法有两种：
+ 一种是基于basic paxos实现的;
+ 另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。

>1. 选举线程由当前`Server`发起选举的线程担任，**其主要功能是对投票结果进行统计，并选出推荐的`Server`**； 
2. 选举线程首先向所有`Server`发起一次询问(包括自己)； 
3. 选举线程收到回复后，验证是否是自己发起的询问(`验证zxid是否一致`)，然后`获取对方的id(myid)`，并存储到当前询问对象列表中，最后获取对方提议的`leader`相关信息(`id,zxid`)，并将这些信息存储到当次选举的投票记录表中； 
4. 收到所有`Server`回复以后，就计算出`zxid`最大的那个`Server`，并将这个`Server`相关信息设置成下一次要投票的`Server`； 
5. 线程将当前`zxid`最大的`Server`设置为当前`Server`要推荐的`Leader`，如果此时获胜的`Server`获得`n/2 + 1`的`Server票`数，设置当前推荐的`leader`为获胜的`Server`，将根据获胜的`Server`相关信息设置自己的状态，否则，继续这个过程，直到`leader`被选举出来。 

通过流程分析我们可以得出：**要使`Leader`获得多数`Server`的支持**，则`Server`总数必须是奇数`2n+1`，且存活的`Server`的数目不得少于`n+1`. 每个`Server`启动后都会重复以上流程。

在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的`server`还会从磁盘快照中恢复数据和会话信息，`zk`会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。

选主的具体流程图所示： 

![basicPaxos.png](/images/basicPaxos.png)

#### `zooKeeper`选主流程（fast paxos）

**fast paxos流程是在选举过程中，`某Server首先向所有Server提议自己要成为leader`，当其它Server收到提议以后，`解决epoch和 zxid的冲突`，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。**

![fastPaxos.png](/images/fastPaxos.png)

#### `zooKeeper`同步流程

>选完Leader以后，zk就进入状态同步过程。 
1. Leader等待server连接； 
2. Follower连接leader，将最大的zxid发送给leader； 
3. Leader根据follower的zxid确定同步点； 
4. 完成同步后通知follower 已经成为uptodate状态； 
5. Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。

##### `zooKeeper`工作流程-Leader

> 1. 恢复数据； 
2. 维持与`Learner`的心跳，接收`Learner`请求并判断`Learner`的请求消息类型； 
3. `Learner`的消息类型主要有`PING消息`、`REQUEST消息`、`ACK消息`、`REVALIDATE消息`，根据不同的消息类型，进行不同的处理。 
   + `PING消息`：指`Learner`的心跳信息；
   + `REQUEST消息`：`Follower`发送的提议信息，包括写请求及同步请求；
   + `ACK消息`： `Follower`的对提议的回复，超过半数的`Follower`通过，则`commit`该提议；
   + `REVALIDATE消息`：用来延长`SESSION`有效时间。


##### `zooKeeper`工作流程-Follower

>`Follower`主要有四个功能： 
1. 向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）； 
2. 接收Leader消息并进行处理； 
3. 接收Client的请求，如果为写请求，发送给Leader进行投票；
4. 返回Client结果。 


>`Follower`的消息循环处理如下几种来自Leader的消息： 
1. `PING消息`： 心跳消息； 
2. `PROPOSAL消息`：Leader发起的提案，要求Follower投票； 
3. `COMMIT消息`：服务器端最新一次提案的信息； 
4. `UPTODATE消息`：表明同步完成； 
5. `REVALIDATE消息`：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息； 
6. `SYNC消息`：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。


